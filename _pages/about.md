---
permalink: /
title: "About Jing-Cheng Pang (庞竟成):"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


<div style="float: right; margin: 10px;">
  <a href="http://www.lamda.nju.edu.cn/"> <img src="../images/lamda_logo.jpg" alt="Your Image" style="max-width: 100px; max-height: 100px;" /> </a>
</div>


I am a fourth-year Ph.D. student at [Nanjing University](https://www.nju.edu.cn/), advised by Professor [Yang Yu](https://www.wolai.com/eyounx/dtR1MTyRXS5tP5Cex4KtdK). In June 2019, I obtained B.Sc. degree from [UESTC](https://www.uestc.edu.cn/). In September 2019, I joined the [LAMDA](https://www.lamda.nju.edu.cn) group led by Professor [Zhi-Hua Zhou](https://cs.nju.edu.cn/zhouzh/index.htm), as a Master's student, excused from the entrance examination. Since September 2021, I was fortunate to be accepted into the Successive Postgraduate and Doctoral program, starting my current Ph.D. studies.
From July to October in 2024, I engaged as a visiting student with Prof. [Masashi Sugiyama](http://www.ms.k.u-tokyo.ac.jp/sugi/)'s team at RIKEN-AIP, Tokyo, Japan.

My research focuses on **_connecting human and intelligent agent (RL-based or LLM-based) through natural language instructions (effective instruction parsing)_**.
Particularly, my study includes:

- Reinforcement Learning: language-conditioned RL, optimization algorithm, imitation learning, applications;
- Large Language Models: training, inference-time optimization, intelligent agent;
- Embodied Robot: home-service robot, sim2real.

Free free to contact/follow me if you are interested in my work. 

## Recent News
- 2025.01: [ReViWo](https://openreview.net/forum?id=vJwjWyt4Ed) for robotics manipulation under viewpoint disturbance, is accepted by ICLR 2025.
- 2025.01: Invited talk at HUAWEI NAIE Group. Topic: RL-driven LLM Optimization and Recent Progress [[slides](/files/slides/RL_driven_LLM.pdf)].
- 2024.12: InCLET is accepted by AAMAS 2025 as a full paper. We will give an oral presentation at Detriot!
- 2024.09: Our work, [KALM](https://openreview.net/forum?id=tb1MlJCY5g), is accepted by NeurIPS 2024! 
- 2024.07: I start my visiting to Prof. [Masashi Sugiyama](http://www.ms.k.u-tokyo.ac.jp/sugi/)'s team at [RIKEN-AIP](https://www.riken.jp/en/research/labs/aip/), Tokyo, Japan, doing RL research
- 2024.01: [RLC](https://openreview.net/forum?id=38E4yUbrgr) for LLM self-improvement is accepted by ICLR 2024
- 2023.11: Awarded as [**Top Reviewer (8%)**](https://nips.cc/Conferences/2023/ProgramCommittee) of NeurIPS 2023
- 2023.09: [TALAR](https://openreview.net/forum?id=bx0SDRVDzF&noteId=E1F2N1w0DO), for instruction-following agents, gets accepted by NeurIPS 2023


## Selected Publications

1. **Jing-Cheng Pang**, Nan Tang, Kaiyuan Li, Yuting Tang, Xin-Qiang Cai, Zhen-Yu Zhang, Gang Niu, Masashi Sugiyama and Yang Yu. Learning View-invariant World Models for Visual Robotic Manipulation. In: *ICLR*, 2025. [[paper](https://openreview.net/forum?id=vJwjWyt4Ed)]
2. **Jing-Cheng Pang**, Si-Hang Yang, Kaiyuan Li, Jiaji Zhang, Xiong-Hui Chen, Nan Tang and Yang Yu. KALM: Knowledgeable Agents by Offline Reinforcement Learning from Large Language Model Rollouts. In: *NeurIPS*, 2024. [[paper](https://openreview.net/forum?id=tb1MlJCY5g)]
3. **Jing-Cheng Pang**, Peng-Yuan Wang, Kaiyuan Li, Xiong-Hui Chen, Jiacheng Xu, Zongzhang Zhang and Yang Yu. Language Model Self-improvement by Reinforcement Learning Contemplation. In: *ICLR*, 2024. [[paper](https://openreview.net/forum?id=38E4yUbrgr)]
4. **Jing-Cheng Pang**, Xinyu Yang, Si-Hang Yang, Xiong-Hui Chen and Yang Yu. Natural Language Instruction-following with Task-related Language Development and Translation. In: *NeurIPS*, 2023. [[paper](https://openreview.net/forum?id=bx0SDRVDzF)]
5. **Jing-Cheng Pang**, Tian Xu, Shengyi Jiang, Yu-Ren Liu and Yang Yu. Reinforcement Learning With Sparse-Executing Actions via Sparsity Regularization. *TNNLS*, to appear. [[paper](https://arxiv.org/pdf/2105.08666)]
6. Peng-Yuan Wang, **Jing-Cheng Pang**, Chen-Yang Wang, Xu-Hui Liu, Tian-Shuo Liu, Si-Hang Yang, Hong Qian and Yang Yu. InCLET: In-context Learning from Language Models can Improve Embodied Instruction-following. In: *AAMAS* (Oral), 2025. [[paper](https://openreview.net/forum?id=qaI22j5mwJ)]


[[Full publication list](/publications/)]


## Projects

<ul>
    <li><strong><a href="https://github.com/lafmdp/Awesome-Papers-Autonomous-Agent" target="_blank">Awesome-Papers-Autonomous-Agent</a></strong>&nbsp;&nbsp;<img style="height:1em" alt="GitHub stars" src="https://img.shields.io/github/stars/lafmdp/Awesome-Papers-Autonomous-Agent?style=social" />
    <br />
    A collection of recent papers on building autonomous agent. Two topics included: RL-based / LLM-based agents.
    </li>
</ul>


