---
permalink: /
title: "About Jing-Cheng Pang (庞竟成):"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<span id="top" style="position: absolute; top: 0; opacity: 0;"></span>

<style>
#top {
  top: -100px;
}
</style>


[[Research Overview](#research-overview)] [[Recent News](#recent-news)] [[Selected Publications](#selected-publications)] [[Projects](#projects)]

---

<div style="float: right; margin: 10px;">
  <a href="http://www.lamda.nju.edu.cn/"> <img src="../images/lamda_logo.jpg" alt="Your Image" style="max-width: 100px; max-height: 100px;" /> </a>
</div>



I am currently an AI Researcher at Huawei, focusing on _building Domain Agent through reinforcement learning and large language models_. I joined Huawei in July 2025 through the [TopMinds](https://career.huawei.com/reccampportal/portal5/topminds.html) Talent Program.
Previously, I received my PhD in June 2025 from [Nanjing University](https://www.nju.edu.cn/) ([LAMDA Group](https://www.lamda.nju.edu.cn)), where I was fortuned to be supervised by Prof. [Yang Yu](https://www.wolai.com/eyounx/dtR1MTyRXS5tP5Cex4KtdK) to conduct reinforcement learning research. In 2024, I was a visiting scholar with Professor [Masashi Sugiyama](http://www.ms.k.u-tokyo.ac.jp/sugi/)'s team at RIKEN-AIP in Tokyo, Japan (July - October).
Prior to that, I obtained my BSc from the University of Electronic Science and Technology of China (UESTC) in June 2019.


## Research Overview

During the PhD phase, my research focuses on **_connecting human and intelligent agent through natural language_**.
By integrating reinforcement learning (RL) and large language models (LLMs), I aim to develop systems that not only interpret human intent but also act autonomously and learn iteratively in dynamic environments.
Particularly, my study includes:

- **Reinforcement Learning**: language-conditioned RL, optimization algorithm, imitation learning, generalist agent;
- **Large Language Models**: model training, inference-time optimization, LLM-based agent;
- **Embodied AI**: home-service robot, sim2real policy learning.

Free free to contact/follow me if you are interested in my work. 

[[Back to top](#top)]

## Recent News
- 2025.07: I join Huawei (AI Data Department) as an AI Researcher, focusing on building Damain Agent with RL and LLMs.
- 2025.06: [ASRE](https://ieeexplore.ieee.org/document/10982133) (for RL optimization) and [LaMSeI](https://openreview.net/forum?id=nnlmcxYWlV) (for LLM application) are accepted by TNNLS and TMLR, respectively.
- 2025.03: Invited talk at HUAWEI Jiaxian Community (稼先社区). Topic: Exploration on Intelligent Agent System based on RL and LLMs [[slides](/files/slides/jiaxian_slides.pdf)].
- 2025.01: [ReViWo](https://openreview.net/forum?id=vJwjWyt4Ed) for robotics manipulation under viewpoint disturbance, is accepted by ICLR 2025.
- 2025.01: Invited talk at HUAWEI NAIE Group. Topic: RL-driven LLM Optimization and Recent Progress [[slides](/files/slides/RL_driven_LLM.pdf)].
- 2024.12: InCLET is accepted by AAMAS 2025 as a full paper. ~~We will give an oral presentation at Detriot~~ (It's a pity that we can not get the visa)!
- 2024.09: Our work, [KALM](https://openreview.net/forum?id=tb1MlJCY5g), is accepted by NeurIPS 2024! 
- 2024.07: I start my visiting to Prof. [Masashi Sugiyama](http://www.ms.k.u-tokyo.ac.jp/sugi/)'s team at [RIKEN-AIP](https://www.riken.jp/en/research/labs/aip/), Tokyo, Japan, doing RL research
- 2024.01: [RLC](https://openreview.net/forum?id=38E4yUbrgr) for LLM self-improvement is accepted by ICLR 2024
- 2023.11: Awarded as [**Top Reviewer (8%)**](https://nips.cc/Conferences/2023/ProgramCommittee) of NeurIPS 2023
- 2023.09: [TALAR](https://openreview.net/forum?id=bx0SDRVDzF&noteId=E1F2N1w0DO), for instruction-following agents, gets accepted by NeurIPS 2023

[[Back to top](#top)]

## Selected Publications

1. **Jing-Cheng Pang**, Nan Tang, Kaiyuan Li, Yuting Tang, Xin-Qiang Cai, Zhen-Yu Zhang, Gang Niu, Masashi Sugiyama and Yang Yu. Learning View-invariant World Models for Visual Robotic Manipulation. In: *ICLR*, 2025. [[paper](https://openreview.net/forum?id=vJwjWyt4Ed)]
2. Peng-Yuan Wang, **Jing-Cheng Pang**, Chen-Yang Wang, Xu-Hui Liu, Tian-Shuo Liu, Si-Hang Yang, Hong Qian and Yang Yu. InCLET: In-context Learning from Language Models can Improve Embodied Instruction-following. In: *AAMAS* (Oral), 2025. [[paper](https://openreview.net/forum?id=qaI22j5mwJ)]
3. **Jing-Cheng Pang**, Si-Hang Yang, Kaiyuan Li, Jiaji Zhang, Xiong-Hui Chen, Nan Tang and Yang Yu. KALM: Knowledgeable Agents by Offline Reinforcement Learning from Large Language Model Rollouts. In: *NeurIPS*, 2024. [[paper](https://openreview.net/forum?id=tb1MlJCY5g)]
4. **Jing-Cheng Pang**, Peng-Yuan Wang, Kaiyuan Li, Xiong-Hui Chen, Jiacheng Xu, Zongzhang Zhang and Yang Yu. Language Model Self-improvement by Reinforcement Learning Contemplation. In: *ICLR*, 2024. [[paper](https://openreview.net/forum?id=38E4yUbrgr)]
5. **Jing-Cheng Pang**, Xinyu Yang, Si-Hang Yang, Xiong-Hui Chen and Yang Yu. Natural Language Instruction-following with Task-related Language Development and Translation. In: *NeurIPS*, 2023. [[paper](https://openreview.net/forum?id=bx0SDRVDzF)]
6. **Jing-Cheng Pang**, Tian Xu, Shengyi Jiang, Yu-Ren Liu and Yang Yu. Reinforcement Learning With Sparse-Executing Actions via Sparsity Regularization. *TNNLS*, to appear. [[paper](https://arxiv.org/pdf/2105.08666)]
7. Shengyi Jiang, **Jing-Cheng Pang** and Yang Yu. Offline Imitation Learning with a Misspecified Simulator. In: *NeurIPS*, 2020. [[paper](https://proceedings.neurips.cc/paper_files/paper/2020/file/60cb558c40e4f18479664069d9642d5a-Paper.pdf)]

[[Full publication list](/publications/)]

[[Back to top](#top)]

## Projects

<ul>
    <li><strong><a href="https://github.com/lafmdp/Awesome-Papers-Autonomous-Agent" target="_blank">Awesome-Papers-Autonomous-Agent</a></strong>&nbsp;&nbsp;<img style="height:1em" alt="GitHub stars" src="https://img.shields.io/github/stars/lafmdp/Awesome-Papers-Autonomous-Agent?style=social" />
    <br />
    A collection of recent papers on building autonomous agent. Two topics included: RL-based / LLM-based agents.
    </li>
    <li><strong><a href="https://github.com/LAMDA-RL/ImagineBench" target="_blank">ImagineBench</a></strong>&nbsp;&nbsp;<img style="height:1em" alt="GitHub stars" src="https://img.shields.io/github/stars/LAMDA-RL/ImagineBench?style=social" />
        <br />
        A benchmark for evaluating RL algorithms that train the policies using both real data and imaginary rollouts from LLMs. 
    </li>
</ul>

[[Back to top](#top)]

